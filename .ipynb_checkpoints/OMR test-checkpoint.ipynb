{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imutils #thru the pip package.\n",
    "# from skimage.filters import threshold_adaptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Toolbox functions-\n",
    "# cv2.createTrackbar('boxDim', 'ImageWindow', 2000, 5000, someFunctionCallBack)\n",
    "\n",
    "def waitQ():\n",
    "    while(cv2.waitKey(1)& 0xFF != ord('q')):pass\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def show(name,img):\n",
    "    cv2.imshow(name,img)\n",
    "    waitQ()\n",
    "    \n",
    "def myColor1():\n",
    "    return (randint(100,250),randint(100,250),randint(100,250))\n",
    "def order_points(pts):\n",
    "\trect = np.zeros((4, 2), dtype = \"float32\")\n",
    "\n",
    "\t# the top-left point will have the smallest sum, whereas\n",
    "\t# the bottom-right point will have the largest sum\n",
    "\ts = pts.sum(axis = 1)\n",
    "\trect[0] = pts[np.argmin(s)]\n",
    "\trect[2] = pts[np.argmax(s)]\n",
    "\tdiff = np.diff(pts, axis = 1)\n",
    "\trect[1] = pts[np.argmin(diff)]\n",
    "\trect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "\t# return the ordered coordinates\n",
    "\treturn rect\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "\t# obtain a consistent order of the points and unpack them\n",
    "\t# individually\n",
    "\trect = order_points(pts)\n",
    "\t(tl, tr, br, bl) = rect\n",
    "\n",
    "\t# compute the width of the new image, which will be the\n",
    "\twidthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "\twidthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "\tmaxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "\t# compute the height of the new image, which will be the\n",
    "\theightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "\theightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "\tmaxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "\t# now that we have the dimensions of the new image, construct\n",
    "\t# the set of destination points to obtain a \"birds eye view\",\n",
    "\t# (i.e. top-down view) of the image, again specifying points\n",
    "\t# in the top-left, top-right, bottom-right, and bottom-left\n",
    "\t# order\n",
    "\tdst = np.array([\n",
    "\t\t[0, 0],\n",
    "\t\t[maxWidth - 1, 0],\n",
    "\t\t[maxWidth - 1, maxHeight - 1],\n",
    "\t\t[0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "\t# compute the perspective transform matrix and then apply it\n",
    "\tM = cv2.getPerspectiveTransform(rect, dst)\n",
    "\twarped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "\t# return the warped image\n",
    "\treturn warped\n",
    "    \n",
    "\n",
    "def readResponse(pts,boxDim,img,threshold=0.5,bord=-1,white=(220,220,220),black=(0,0,0)):\n",
    "    _, t = cv2.threshold(img,100,255,cv2.THRESH_BINARY)\n",
    "    w,h=boxDim\n",
    "    mask = 255*np.ones(boxDim, np.uint8)\n",
    "    ret = {}\n",
    "    for pt in pts:\n",
    "        pt = tuple(map(int,pt))\n",
    "        x,y=pt \n",
    "        crop=img[y:y+h,x:x+w]\n",
    "        mean_color = cv2.mean(crop,mask)\n",
    "        ret[pt]= mean_color[0]/255#\n",
    "        clr = black if threshold > mean_color[0]/255 else white\n",
    "        cv2.rectangle(img,pt,(x+w,y+h),clr,bord)#-1 is for fill\n",
    "    return ret\n",
    "def calcGaps(PointsX,PointsY,numsX,numsY):\n",
    "    gapsX = ( abs(PointsX[0]-PointsX[1])/(numsX[0]-1),abs(PointsX[2]-PointsX[3]) )\n",
    "    gapsY = ( abs(PointsY[0]-PointsY[1])/(numsY[0]-1),abs(PointsY[2]-PointsY[3]) )\n",
    "    return (gapsX,gapsY)\n",
    "\n",
    "def maketemplate(start,numsX,numsY,gapsX,gapsY):\n",
    "    templateMCQ=[]\n",
    "    posx=start[0]\n",
    "    for x in range(numsX[1]):\n",
    "        posy=start[1]\n",
    "        for y in range(numsY[1]):\n",
    "            templateMCQ.append((posx,posy))\n",
    "            posy+= (gapsY[1] if ((y+1) % numsY[0]==0) else gapsY[0])\n",
    "        posx+= (gapsX[1] if ((x+1) % numsX[0]==0) else gapsX[0])\n",
    "    return templateMCQ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmouse_and_match - template matching\\nlk_track - draw in the air\\nlk_homography - see good features\\ngabor_threads - that fantasy tiger wallpaper\\nfloodfill -> That paint bucket is this one\\n'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Good ones from opencv SAMPLES -\n",
    "\"\"\"\n",
    "mouse_and_match - template matching\n",
    "lk_track - draw in the air\n",
    "lk_homography - see good features\n",
    "gabor_threads - that fantasy tiger wallpaper\n",
    "floodfill -> That paint bucket is this one\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 15]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=(0.5,1.5)\n",
    "map(int,np.multiply(a,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def someFunctionCallBack(*arg):\n",
    "    readResponse(pts,(boxDimX,boxDimY),img,threshold=0.55,bord=-1)\n",
    "\n",
    "def match_template_scaled(img1, template,pts=4,scaleRange=(0.5,1.5),fac=100,threshold=0.6,CLR=(0,255,255),iterLim=30):\n",
    "    orig=template.copy()\n",
    "    w1,h1,_=img1.shape\n",
    "    w,h,_=template.shape\n",
    "    scale=float(h1)/h\n",
    "    print('initial scale',scale)\n",
    "    x=map(int,np.multiply(scaleRange,fac))\n",
    "    if((x[1]-x[0])> iterLim*fac/10):\n",
    "        print(\"Too many iterations : %d, reduce scaleRange\" % ((x[1]-x[0])*10/fac) )\n",
    "        return []\n",
    "    r_max=None\n",
    "    for r0 in range(x[0],x[1],fac/10):\n",
    "        r=float(r0)/fac\n",
    "        print(r)\n",
    "        if(r==0.0):\n",
    "            continue\n",
    "        templ = imutils.resize(orig, height = int(h*r))\n",
    "        res = cv2.matchTemplate(img1,templ,cv2.TM_CCOEFF_NORMED)\n",
    "#         cv2.imshow('res',res)        waitQ()\n",
    "        maxT = res.max()\n",
    "        if(threshold < maxT):\n",
    "            print('%d)max_match %d%%' % (r0,100*maxT))\n",
    "            r_max=r\n",
    "            threshold = maxT\n",
    "    if(r_max==None):\n",
    "        print(\"No matchings for given threshold\")\n",
    "        return []\n",
    "        \n",
    "    print('final scale',r_max)\n",
    "    templ = imutils.resize(orig, height = int(h*r_max))\n",
    "    res = cv2.matchTemplate(img1,templ,cv2.TM_CCOEFF_NORMED)# better than TM_CCOEFF_NORMED)\n",
    "    cv2.imshow('res',res)    \n",
    "    waitQ()\n",
    "    res2  =  res.flatten()\n",
    "    threshold = min(res2[np.argpartition(res2, -pts)[-pts:]])\n",
    "    loc = np.where(res>=threshold) \n",
    "#     print(loc)\n",
    "    w,h,_=templ.shape\n",
    "    centres=[]\n",
    "    for pt in zip(*loc[::-1]):\n",
    "        cv2.rectangle(img1,pt,(pt[0]+w,pt[1]+h),CLR,2)\n",
    "        centres.append([pt[0]+w/2,pt[1]+h/2])\n",
    "    cv2.imshow('detected',img1)\n",
    "    waitQ()\n",
    "    return np.array(centres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 494, 3)\n",
      "(21, 74, 3)\n",
      "('initial scale', 6.675675675675675)\n",
      "0.95\n",
      "95)max_match 30%\n",
      "1.05\n",
      "105)max_match 30%\n",
      "1.15\n",
      "1.25\n",
      "1.35\n",
      "1.45\n",
      "('final scale', 1.05)\n"
     ]
    }
   ],
   "source": [
    "orig = cv2.imread('FinaltechnoOMR.jpg') #,cv2.CV_8UC1/IMREAD_COLOR/UNCHANGED\n",
    "template = cv2.imread('test.png') #,cv2.CV_8UC1/IMREAD_COLOR/UNCHANGED\n",
    "image=orig.copy()\n",
    "show('temp',template)\n",
    "image = imutils.resize(image, height = 700)\n",
    "image=image-cv2.erode(image,None)\n",
    "template=template-cv2.erode(template,None)\n",
    "print(image.shape)\n",
    "print(template.shape)\n",
    "# cv2.createTrackbar('boxDim', 'ImageWindow', 2000, 5000, match_template_scaled_with_time_flag)\n",
    "p=image.shape[1]/template.shape[1]\n",
    "four_pts =match_template_scaled(image,template,pts=1,scaleRange=(0.95,1.5),fac=100,threshold=0.55,iterLim=50)\n",
    "if(len(four_pts)):\n",
    "    warped = four_point_transform(orig, four_pts)\n",
    "# warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134,94) : (134,94)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:59: RuntimeWarning: Mean of empty slice.\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now dvlpments-\n",
    "If multi-marked, try lower threshold, if still get multiple dark, move on, else choose the most dark one.\n",
    "Make a questions class - It has options & their (4 by default) coordinates\n",
    "pass array of questions to readResponse : it just reads the coords and updates whether its marked or not.\n",
    "\n",
    "\"\"\"\n",
    "drawing = False # true if mouse is pressed\n",
    "mode = True # if True, draw rectangle. Press 'm' to toggle to curve\n",
    "ix,iy = -1,-1\n",
    "fx,fy = -1,-1\n",
    "erase= True\n",
    "\n",
    "# mouse callback function\n",
    "def draw_rect(event,x,y,flags,param):\n",
    "    global ix,iy,fx,fy,drawing,mode,mask\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix,iy = x,y\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing == True:\n",
    "            cv2.rectangle(mask,(ix,iy),(x,y),(0,0,0),-1)\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        if(erase):\n",
    "            mask = np.zeros_like(mask)\n",
    "        print(\"(%d,%d) : (%d,%d)\" % (ix,iy,x,y))\n",
    "        cv2.putText(mask,(\"(%d,%d) : (%d,%d)\" % (ix,iy,x,y)),(10,30),cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1.0,(0,250,100),2)\n",
    "        fx,fy=x,y\n",
    "        cv2.rectangle(mask,(ix,iy),(fx,fy),(0,0,0),-1)\n",
    "# image was grayscale\n",
    "img = warped#np.zeros(warped.shape, np.uint8)\n",
    "mask = np.zeros(img.shape, np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image',draw_rect)\n",
    "pts1=[]\n",
    "pts2=[]\n",
    "while(1):\n",
    "    cv2.imshow('image',cv2.subtract(img,mask))\n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "    elif k == ord('x'):\n",
    "        erase=not erase\n",
    "        \n",
    "    elif k == ord('a'):\n",
    "        pt1,pt2=(ix,iy),(fx,fy)        \n",
    "        print(\"added\",pt1,pt2)\n",
    "        pts1.append(pt1)\n",
    "        pts2.append(pt2)\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "pt1,pt2=np.array(pts1).mean(),np.array(pts2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((18, 26.75), (9, 18.25))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nNote : You'll get this error if the code is accessing pixels out of bounds of the image\\nerror: (-215) A.size == arrays[i0]->size in function init\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mktempl(pX,pY,nX,nY):\n",
    "    gapsX,gapsY=calcGaps(pX,pY,nX,nY)\n",
    "    return maketemplate((pX[0],pY[0]),nX,nY,gapsX,gapsY)\n",
    "\n",
    "img = cv2.imread('technoOMR_marked.jpg',cv2.CV_8UC1) #IMREAD_COLOR/UNCHANGED\n",
    "h,w =img.shape\n",
    "PointsX,PointsY = (38,92,92,118.75),(352,388,388,406.25)\n",
    "gapsX,gapsY=calcGaps(PointsX,PointsY,(4,20),(5,20))\n",
    "print(gapsX,gapsY)\n",
    "# PointsX will have only x coords of the horiz points\n",
    "t=mktempl(PointsX,PointsY,(4,20),(5,20))\n",
    "g1,g2=calcGaps((265,282,282,310),(236,317,236,317),(2,4),(10,10))\n",
    "t1=maketemplate((265,236),(2,4),(10,10),g1,g2)\n",
    "t2=maketemplate((355,236),(2,4),(10,10),(g1[0]*1.13,g1[0]),g2)\n",
    "t3=maketemplate((355,236),(2,4),(10,10),(g1[0]*1.13,g1[0]),g2)\n",
    "# t3=maketemplate((30,90),(25,25),(26,26),(9,9),PointsY)\n",
    "pts=t+t1+t2\n",
    "boxDimX,boxDimY=(6,6)\n",
    "readResponse(pts,(boxDimX,boxDimY),img,threshold=0.55,bord=-1)\n",
    "cv2.imshow('imageWindow',img)\n",
    "# cv2.createTrackbar('boxDimY', 'imageWindow', 6, 10, someFunctionCallBack)\n",
    "\n",
    "waitQ()\n",
    "\"\"\"\n",
    "Note : You'll get this error if the code is accessing pixels out of bounds of the image\n",
    "error: (-215) A.size == arrays[i0]->size in function init\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPseudo code- Sound and Simple\\nImage processing to :\\n    Done using getPerspectiveTransform> Scale and rotate image correctly\\n    Detect responses correctly-\\n        Check if bubble size bigger than threshold\\n    Return the response to each question in a list.\\nPure python to :\\n    Check the answers\\n    Provide a GUI ? (tkinker)\\n    >Web interface preferred\\n    \\n    \\nBut first, get going with a static template and read the color\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pseudo code- Sound and Simple\n",
    "Image processing to :\n",
    "    Done using getPerspectiveTransform> Scale and rotate image correctly\n",
    "    Detect responses correctly-\n",
    "        Check if bubble size bigger than threshold\n",
    "    Return the response to each question in a list.\n",
    "Pure python to :\n",
    "    Check the answers\n",
    "    Provide a GUI ? (tkinker)\n",
    "    >Web interface preferred\n",
    "    \n",
    "    \n",
    "But first, get going with a static template and read the color\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('OMRMarked.jpg',cv2.CV_8UC1) #IMREAD_COLOR/UNCHANGED\n",
    " \n",
    "#---- 4 corner points of the bounding box\n",
    "pts_src = np.array([[17.0,0.0], [77.0,5.0], [0.0, 552.0],[53.0, 552.0]])\n",
    "\n",
    "#---- 4 corner points of the black image you want to impose it on\n",
    "pts_dst = np.array([[0.0,0.0],[77.0, 0.0],[ 0.0,552.0],[77.0, 552.0]])\n",
    "\n",
    "#---- forming the black image of specific size\n",
    "im_dst = np.zeros((552, 77, 3), np.uint8)\n",
    "\n",
    "#---- Framing the homography matrix\n",
    "h, status = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "#---- transforming the image bound in the rectangle to straighten\n",
    "im_out = cv2.warpPerspective(img, h, (im_dst.shape[1],im_dst.shape[0]))\n",
    "cv2.imshow(\"im_out.jpg\", im_out)\n",
    "waitQ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#underscore consumes the variable - retval here\n",
    "img = cv2.imread('OMRSample.jpg',cv2.CV_8UC1) #IMREAD_COLOR/UNCHANGED\n",
    "#retval, threshold = cv2.threshold(img,signumThrVal,maxVal,cv2.THRESH_BINARY_INV)\n",
    "threshold=[]\n",
    "_, t = cv2.threshold(img,100,255,cv2.THRESH_BINARY)\n",
    "threshold.append(t)\n",
    "threshold.append(cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,115,1))\n",
    "ret, t = cv2.threshold(img,126,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "threshold.append(t)\n",
    "cv2.imshow('imageWindow',img)\n",
    "\n",
    "for i in range(0,3):\n",
    "    cv2.imshow('th'+str(i),threshold[i]);\n",
    "    cv2.moveWindow('th'+str(i),1280,0)\n",
    "\n",
    "waitQ()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-11-cb9646df0e0a>, line 60)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-cb9646df0e0a>\"\u001b[0;36m, line \u001b[0;32m60\u001b[0m\n\u001b[0;31m    waitQ()\u001b[0m\n\u001b[0m           \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Cam Scanner Code \n",
    "image = cv2.imread('OMRTemp.jpg') #,cv2.CV_8UC1/IMREAD_COLOR/UNCHANGED\n",
    "ratio = image.shape[0] / 500.0\n",
    "orig = image.copy()\n",
    "image = imutils.resize(image, height = 500)\n",
    " \n",
    "# convert the image to grayscale, blur it, and find edges\n",
    "# in the image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edged = cv2.Canny(gray, 75, 200)\n",
    " \n",
    "# show the original image and the edge detected image\n",
    "# print \"STEP 1: Edge Detection\"\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.imshow(\"Edged\", edged)\n",
    "waitQ()\n",
    "\n",
    "# find the contours in the edged image, keeping only the\n",
    "# largest ones, and initialize the screen contour\n",
    "# try mode= CV_RETR_EXTERNAL \n",
    "_ , cnts ,_ = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#The hack -\n",
    "cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:min(5,len(cnts))] # get top 5 largest contours by area\n",
    "\n",
    "# loop over the contours\n",
    "for c in cnts:\n",
    "\t# approximate the contour\n",
    "\tperi = cv2.arcLength(c, True)\n",
    "\tapprox = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "\n",
    "\t# if our approximated contour has four points, then we\n",
    "\t# can assume that we have found our screen\n",
    "\tif len(approx) == 4:\n",
    "\t\tscreenCnt = approx\n",
    "\t\tbreak\n",
    "\n",
    "# show the contour (outline) of the piece of paper\n",
    "print \"STEP 2: Find contours of paper\"\n",
    "cv2.drawContours(image, [screenCnt], -1, (244, 255, 0), 2)\n",
    "cv2.imshow(\"Outline\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# apply the four point transform to obtain a top-down\n",
    "# view of the original image\n",
    "warped = four_point_transform(orig, screenCnt.reshape(4, 2) * ratio)\n",
    "\n",
    "# convert the warped image to grayscale, then threshold it\n",
    "# to give it that 'black and white' paper effect\n",
    "warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "# warped = threshold_adaptive(warped, 251, offset = 10)\n",
    "# warped = cv2.adaptiveThreshold(warped,25,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,115,1)\n",
    "warped = warped.astype(\"uint8\") * 255\n",
    " \n",
    "# show the original and scanned images\n",
    "print \"STEP 3: Apply perspective transform\"\n",
    "cv2.imshow(\"Original\", imutils.resize(orig, height = 650))\n",
    "cv2.imshow(\"Scanned\", imutils.resize(warped, height = 650))\n",
    "waitQ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Template Matching Code-\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv2.imread('technoOMR_marked.jpg',0)\n",
    "img2 = img.copy()\n",
    "template = cv2.imread('circle.jpg',0)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "# All the 6 methods for comparison in a list\n",
    "methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',\n",
    "            'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "for meth in methods:\n",
    "    img = img2.copy()\n",
    "    method = eval(meth)\n",
    "    # Apply template Matching\n",
    "    res = cv2.matchTemplate(img,template,method)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "    # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "        top_left = min_loc\n",
    "    else:\n",
    "        top_left = max_loc\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    cv2.rectangle(img,top_left, bottom_right, 0, 2)\n",
    "    plt.subplot(121),plt.imshow(res,cmap = 'gray')\n",
    "    \n",
    "    plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    "    plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\n",
    "    plt.suptitle(meth)\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
