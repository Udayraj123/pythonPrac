Recap of ML2
Random Forest - CHECKS IMPORTANCE OF THE VARIABLES. Multiple Classfn Trees
	mtry = count(Features) is one randomness other is  ntress = no of trees
	Bootstrapping = N samples from training set, then construct a tree. No of trees to construct, P random attributes chosen
	Bagging = Majority = Bootstrapped

[Task 0 ] : Read all * marks from video lectures.
[Task 1 ] : Boosting + Adaboost ( will be asked in next lec.)



HOW TO:
Imputation = Filling Missing
Also make Outliers (obv wrongs DOB= 2034) into NA values
=ALong with empty ones, remove near zero variance variables.
mice can do Imputation in Demographic variables

Usage of Unsupervised = clustering the users into segments Then do separate modelling pon the segments.


TN : True Negatives,etc.
True Negatives Rate = Specificity = TN/(TN + FP) = 1 - FPR
True Positives Rate = Sensitivity  = TP/(TP + FN) = 1 - FNR
Receiver Operating Characteristics = Curve between TPR and FPR
area under ROC = 


K means clustering = More than 2 clusters
	how: randomly initialize three points and  Put Datapoints into each points bucket
	CP = complexity parameter	

makeCluster(4)

Cart = classification and Regression Trees
GBM = Gradient Boost Machine


install pkg
rpart
xgboost
e1071 

Go thru the videos 

Take Part in comps -
& See tutorials on -
binary clsf =titanic wala
Regression = forest wala(1st)

Course -
Analytics Edge
Analytics Vidya